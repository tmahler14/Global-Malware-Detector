{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Graph Builder\n",
    "\n",
    "### Step #3.) Combines the nodes from the MapNodesBuilder and constructs global graphs\n",
    "\n",
    "#### Tim Mahler & Atreya Misra\n",
    "#### Final Project\n",
    "#### Security EE382V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Import libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ast\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hide Warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node Class\n",
    "\"\"\"\n",
    "    \"node\" : {\n",
    "        \"name\" : id of Symantec file,\n",
    "        \"sha2\" : id of Symantec file SHA2,\n",
    "        \"md5\" : id of Symantec file MD5,\n",
    "        \"prob\" : probability of the node,\n",
    "        \"outcomes\" : total outcomes of malicious,\n",
    "        \"tests\" : total number of tests run\n",
    "        \"is_malicious\" : true value if malicious or not,\n",
    "        \"machine\" : <Set of machine id's where the file was found>,\n",
    "        \"predicted\" : predicted value, 1 is malicious,\n",
    "        \"ts\" : timestamp\n",
    "    },\n",
    "    \"parent\" : {\n",
    "        <node id of child> : <Edge value: Domain name>\n",
    "    },\n",
    "    \"child\" : {\n",
    "        <node id of child> : <Edge value: Domain name>\n",
    "    },\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, node):\n",
    "        self.node = node\n",
    "        self.parent = {}\n",
    "        self.child = {}\n",
    "        self.machine = set()\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Node: \"+str(self.node)+\", children = \"+str(self.child)+\", parent = \"+str(self.parent)+\", machine = \"+str(self.machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the Node Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading nodes from file: ../data/mapped_nodes/mapped_nodes_0_2018-12-13_20-38-27.csv\n",
      "Reading nodes from file: ../data/mapped_nodes/mapped_nodes_1_2018-12-13_20-38-27.csv\n",
      "Reading nodes from file: ../data/mapped_nodes/mapped_nodes_2_2018-12-13_20-38-27.csv\n",
      "Reading nodes from file: ../data/mapped_nodes/mapped_nodes_3_2018-12-13_20-38-27.csv\n",
      "0\n",
      "1435936\n"
     ]
    }
   ],
   "source": [
    "all_nodes = {}\n",
    "bad_nodes = 0\n",
    "\n",
    "# Parse node\n",
    "def parse_node_data(node):\n",
    "    global bad_nodes\n",
    "    try:\n",
    "        if \"total\" not in node[\"node\"]:\n",
    "            node[\"node\"][\"total\"] = 50\n",
    "            \n",
    "            if \"malicious\" in node[\"node\"]:\n",
    "                \n",
    "                if node[\"node\"][\"malicious\"]:\n",
    "                    node[\"node\"][\"outcomes\"] = 40\n",
    "                    node[\"node\"][\"prob\"] = 0.8\n",
    "                else:\n",
    "                    node[\"node\"][\"outcomes\"] = 10\n",
    "                    node[\"node\"][\"prob\"] = 0.2\n",
    "            else:\n",
    "                # Bad node\n",
    "                bad_nodes += 1\n",
    "                return None\n",
    "        \n",
    "        n = Node({\n",
    "            \"name\" : node[\"node\"][\"name\"],\n",
    "            \"ts\" : node[\"node\"][\"ts\"],\n",
    "            \"outcomes\" : node[\"node\"][\"outcomes\"] if \"outcomes\" in node[\"node\"] else 50,\n",
    "            \"total\" : node[\"node\"][\"total\"],\n",
    "            \"prob\" : node[\"node\"][\"prob\"]\n",
    "        })\n",
    "        n.child = node[\"child\"]\n",
    "        n.parent = node[\"parent\"]\n",
    "\n",
    "        return n\n",
    "    except:\n",
    "        bad_nodes += 1\n",
    "#         print (node)\n",
    "        return None\n",
    "\n",
    "# Read in the data from the nodes file and store in temp variable\n",
    "def read_mapped_node_data(file):\n",
    "    global all_nodes, bad_nodes\n",
    "    \n",
    "    print (\"Reading nodes from file: \"+file)\n",
    "    \n",
    "    with open(file) as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        csv_lines = []\n",
    "        \n",
    "        for i, row in enumerate(readCSV):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            \n",
    "            # Else parse the mapping\n",
    "            node_info = ast.literal_eval(row[0])\n",
    "            \n",
    "            #print (node_info)\n",
    "            \n",
    "            new_node = parse_node_data(node_info)\n",
    "            \n",
    "            #print (new_node)\n",
    "            if new_node:\n",
    "                all_nodes[new_node.node[\"name\"]] = new_node\n",
    "    \n",
    "\n",
    "# Read in all of the files\n",
    "read_mapped_node_data(\"../data/mapped_nodes/mapped_nodes_0_2018-12-13_20-38-27.csv\")seached_node\n",
    "read_mapped_node_data(\"../data/mapped_nodes/mapped_nodes_1_2018-12-13_20-38-27.csv\")\n",
    "read_mapped_node_data(\"../data/mapped_nodes/mapped_nodes_2_2018-12-13_20-38-27.csv\")\n",
    "read_mapped_node_data(\"../data/mapped_nodes/mapped_nodes_3_2018-12-13_20-38-27.csv\")\n",
    "\n",
    "print (bad_nodes)\n",
    "print (len(all_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constrcut Global Graphs Given Nodes\n",
    "\n",
    "\n",
    "#### Loop through the nodes and construct global graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10000 size remain:125926\n",
      "Iteration:20000 size remain:158206\n",
      "Iteration:30000 size remain:153084\n",
      "Iteration:40000 size remain:146076\n",
      "Iteration:50000 size remain:138201\n",
      "Iteration:60000 size remain:130064\n",
      "Iteration:70000 size remain:121908\n",
      "Iteration:80000 size remain:113499\n",
      "Iteration:90000 size remain:105468\n",
      "Iteration:100000 size remain:96334\n",
      "Iteration:110000 size remain:88121\n",
      "Iteration:120000 size remain:81139\n",
      "Iteration:130000 size remain:798943\n",
      "Iteration:140000 size remain:917998\n",
      "Iteration:150000 size remain:908332\n",
      "Iteration:160000 size remain:911935\n",
      "Iteration:170000 size remain:910972\n",
      "Iteration:180000 size remain:932013\n",
      "Iteration:190000 size remain:960207\n",
      "Iteration:200000 size remain:969131\n",
      "Iteration:210000 size remain:962759\n",
      "Iteration:220000 size remain:955914\n",
      "Iteration:230000 size remain:947414\n",
      "Iteration:240000 size remain:939622\n",
      "Iteration:250000 size remain:933258\n",
      "Iteration:260000 size remain:925882\n",
      "Iteration:270000 size remain:918248\n",
      "Iteration:280000 size remain:910027\n",
      "Iteration:290000 size remain:901499\n",
      "Iteration:300000 size remain:892645\n",
      "Iteration:310000 size remain:883911\n",
      "Iteration:320000 size remain:875086\n",
      "Iteration:330000 size remain:866832\n",
      "Iteration:340000 size remain:858274\n",
      "Iteration:350000 size remain:849210\n",
      "Iteration:360000 size remain:840096\n",
      "Iteration:370000 size remain:830780\n",
      "Iteration:380000 size remain:821107\n",
      "Iteration:390000 size remain:812286\n",
      "Iteration:400000 size remain:803992\n",
      "Iteration:410000 size remain:795454\n",
      "Iteration:420000 size remain:787004\n",
      "Iteration:430000 size remain:777595\n",
      "Iteration:440000 size remain:768066\n",
      "Iteration:450000 size remain:758892\n",
      "Iteration:460000 size remain:749590\n",
      "Iteration:470000 size remain:740340\n",
      "Iteration:480000 size remain:730847\n",
      "Iteration:490000 size remain:722202\n",
      "Iteration:500000 size remain:712650\n",
      "Iteration:510000 size remain:702768\n",
      "Iteration:520000 size remain:693164\n",
      "Iteration:530000 size remain:683925\n",
      "Iteration:540000 size remain:674591\n",
      "Iteration:550000 size remain:665225\n",
      "Iteration:560000 size remain:656186\n",
      "Iteration:570000 size remain:648159\n",
      "Iteration:580000 size remain:638563\n",
      "Iteration:590000 size remain:628762\n",
      "Iteration:600000 size remain:618957\n",
      "Iteration:610000 size remain:609156\n",
      "Iteration:620000 size remain:599448\n",
      "Iteration:630000 size remain:589526\n",
      "Iteration:640000 size remain:579579\n",
      "Iteration:650000 size remain:569852\n",
      "Iteration:660000 size remain:561797\n",
      "Iteration:670000 size remain:552546\n",
      "Iteration:680000 size remain:542963\n",
      "Iteration:690000 size remain:533394\n",
      "Iteration:700000 size remain:524144\n",
      "Iteration:710000 size remain:514524\n",
      "Iteration:720000 size remain:504928\n",
      "Iteration:730000 size remain:495537\n",
      "Iteration:740000 size remain:485747\n",
      "Iteration:750000 size remain:476405\n",
      "Iteration:760000 size remain:466724\n",
      "Iteration:770000 size remain:456915\n",
      "Iteration:780000 size remain:447184\n",
      "Iteration:790000 size remain:437457\n",
      "Iteration:800000 size remain:427569\n",
      "Iteration:810000 size remain:417628\n",
      "Iteration:820000 size remain:407740\n",
      "Iteration:830000 size remain:398071\n",
      "Iteration:840000 size remain:389289\n",
      "Iteration:850000 size remain:379675\n",
      "Iteration:860000 size remain:370449\n",
      "Iteration:870000 size remain:360766\n",
      "Iteration:880000 size remain:350961\n",
      "Iteration:890000 size remain:341575\n",
      "Iteration:900000 size remain:332207\n",
      "Iteration:910000 size remain:322460\n",
      "Iteration:920000 size remain:314301\n",
      "Iteration:930000 size remain:304732\n",
      "Iteration:940000 size remain:295059\n",
      "Iteration:950000 size remain:286047\n",
      "Iteration:960000 size remain:276583\n",
      "Iteration:970000 size remain:270033\n",
      "Iteration:980000 size remain:260910\n",
      "Iteration:990000 size remain:252989\n",
      "Iteration:1000000 size remain:244024\n",
      "Iteration:1010000 size remain:234736\n",
      "Iteration:1020000 size remain:226550\n",
      "Iteration:1030000 size remain:217591\n",
      "Iteration:1040000 size remain:209701\n",
      "Iteration:1050000 size remain:202131\n",
      "Iteration:1060000 size remain:196609\n",
      "Iteration:1070000 size remain:190853\n",
      "Iteration:1080000 size remain:188091\n",
      "Iteration:1090000 size remain:181602\n",
      "Iteration:1100000 size remain:172424\n",
      "Iteration:1110000 size remain:163395\n",
      "Iteration:1120000 size remain:154090\n",
      "Iteration:1130000 size remain:145550\n",
      "Iteration:1140000 size remain:136549\n",
      "Iteration:1150000 size remain:127542\n",
      "Iteration:1160000 size remain:119047\n",
      "Iteration:1170000 size remain:110337\n",
      "Iteration:1180000 size remain:109499\n",
      "Iteration:1190000 size remain:102068\n",
      "Iteration:1200000 size remain:95635\n",
      "Iteration:1210000 size remain:92505\n",
      "Iteration:1220000 size remain:88142\n",
      "Iteration:1230000 size remain:84757\n",
      "Iteration:1240000 size remain:80182\n",
      "Iteration:1250000 size remain:74792\n",
      "Iteration:1260000 size remain:67057\n",
      "Iteration:1270000 size remain:58334\n",
      "Iteration:1280000 size remain:52628\n",
      "Iteration:1290000 size remain:44054\n",
      "Iteration:1300000 size remain:37330\n",
      "Iteration:1310000 size remain:29584\n",
      "Iteration:1320000 size remain:21428\n",
      "Iteration:1330000 size remain:13847\n",
      "Iteration:1340000 size remain:8385\n",
      "Iteration:1350000 size remain:2095\n",
      "DONE finding graph\n",
      "Num nodes = 1354658\n"
     ]
    }
   ],
   "source": [
    "graphs = []\n",
    "\n",
    "# Remove the nodes from all of the nodes once graph is found\n",
    "def remove_nodes(nodes):\n",
    "    \n",
    "    # For each one of the nodes found in the graph, remove from total nodes\n",
    "    for n in nodes:\n",
    "        all_nodes.pop(n.node[\"name\"], None)\n",
    "        \n",
    "    \n",
    "# Given the list of nodes, construct a global graph\n",
    "def construct_global_graph():\n",
    "    graph = {}\n",
    "    remaining_nodes = {}\n",
    "    \n",
    "    done = False\n",
    "    n_keys = list(all_nodes.keys())\n",
    "    first_node = all_nodes[n_keys[0]]\n",
    "    \n",
    "    remaining_nodes[first_node.node[\"name\"]] = False\n",
    "    \n",
    "#     print (first_node)\n",
    "#     print (graph)\n",
    "    \n",
    "    # While not done, find nodes\n",
    "    i = 0\n",
    "    while not done:\n",
    "        i += 1\n",
    "        \n",
    "        if (i % 10000 == 0):\n",
    "            print (\"Iteration:\"+str(i)+\" size remain:\"+str(len(remaining_nodes)))\n",
    "                        \n",
    "        # Determine if done by seeing if no nodes remain\n",
    "        done = True\n",
    "        for k, v in remaining_nodes.items():\n",
    "            done = False\n",
    "            seached_node = all_nodes[k]\n",
    "#             print (\"Finding items for the node:\" + k)\n",
    "#             print (seached_node)\n",
    "#             print(\"\")\n",
    "            break\n",
    "    \n",
    "        # If not done, then add all children and parents for the given node\n",
    "        if not done:\n",
    "            # Add parents for the given node\n",
    "            for k2, v2 in seached_node.parent.items():\n",
    "\n",
    "                # Add node if not already in graph\n",
    "                if k2 not in graph and k2 not in remaining_nodes and k2 in all_nodes:\n",
    "                    remaining_nodes[k2] = False\n",
    "\n",
    "            # Add children for the given node\n",
    "            for k3, v3 in seached_node.child.items():\n",
    "\n",
    "                # Add node if not already in graph\n",
    "                if k3 not in graph and k3 not in remaining_nodes and k3 in all_nodes:\n",
    "                    remaining_nodes[k3] = False\n",
    "                    \n",
    "            \n",
    "            remaining_nodes.pop(seached_node.node[\"name\"], None) # Remove from remaining nodes\n",
    "            graph[seached_node.node[\"name\"]] = True # Add node to graph\n",
    "        \n",
    "#         print (remaining_nodes)\n",
    "#         print (graph)\n",
    "#         print(\"-----------------\\n\")\n",
    "        \n",
    "#         if (i == 5):\n",
    "#             done = True\n",
    "   \n",
    "    print (\"DONE finding graph\")\n",
    "    print (\"Num nodes = \"+str(len(graph)))\n",
    "    return graph\n",
    "        \n",
    "\n",
    "# Step #1 Constrcut global graph\n",
    "global_graph = construct_global_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1354658\n",
      "3487117\n",
      "Writing global graph to file: ../data/global_graphs/global_graph_2018-12-15_18-09-54.csv\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "save_graph = {\n",
    "    \"nodes\" : [],\n",
    "    \"edges\" : []\n",
    "}\n",
    "directory = \"../data/global_graphs\"\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "NEW_FILE_NAME = directory+\"/global_graph_\"+time.strftime(\"%Y-%m-%d_%H-%M-%S\")+\".csv\"\n",
    "\n",
    "# Write to the csv\n",
    "def write_to_csv(file_name, data):\n",
    "    print (\"Writing global graph to file: \"+NEW_FILE_NAME)\n",
    "    # Write new line to the csv file\n",
    "    with open(file_name, \"w\") as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(data)\n",
    "\n",
    "\n",
    "def build_graph_csv():\n",
    "    global save_graph\n",
    "    i = 0\n",
    "    for node_key in global_graph:\n",
    "        i += 1\n",
    "        # Add node to csv graph\n",
    "        n = all_nodes[node_key]\n",
    "        save_graph[\"nodes\"].append(n.node)\n",
    "        \n",
    "        # Add edges for children\n",
    "        for c, v in n.child.items():\n",
    "            save_graph[\"edges\"].append({\"source\" : node_key, \"target\" : c, \"url\" : v})\n",
    "        \n",
    "        #print (node_key)\n",
    "        \n",
    "        \n",
    "# build the csv data\n",
    "build_graph_csv()\n",
    "\n",
    "print (len(save_graph[\"nodes\"]))\n",
    "print (len(save_graph[\"edges\"]))\n",
    "\n",
    "# Write to csv\n",
    "write_to_csv(NEW_FILE_NAME, [save_graph])\n",
    "print (\"DONE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
